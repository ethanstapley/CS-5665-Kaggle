{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4922a396-2941-4234-8c3b-e9ba2eac00fd",
   "metadata": {},
   "source": [
    "# Jigsaw Rate Severity of Toxic Comments | Checkpoint 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f813c09-6f13-42a4-8f63-e83839d03a59",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "970e242f-70ff-4de5-a183-c93d58fa73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "import torch.cuda.amp as amp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81addd5-f392-4252-b1f7-e7ac33e9c217",
   "metadata": {},
   "source": [
    "##### Checking for cuda and clearing cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a5d5260-20d5-48f7-b1aa-746f180956e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check CUDA availability and set device\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d451852-553b-4951-a437-6f07f406203a",
   "metadata": {},
   "source": [
    "#### Loading the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbd8ae95-2f95-45f6-a09b-4e062be12cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Sample:\n",
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "print(\"Train Data Sample:\")\n",
    "print(train_df.head())\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086bdd45-8688-441c-89af-9e4640f7ea4a",
   "metadata": {},
   "source": [
    "#### Cleaning text | Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9db3de7a-a81c-4954-8b63-3cc8c4c767b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning of the text\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text) # REmoves special characters\n",
    "    return text\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"comment_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e74140-6ff6-4208-be91-511e74c62d89",
   "metadata": {},
   "source": [
    "## Creating Pytorch Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc37d900-4ce3-48ef-9e38-d1bcec891571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "class ToxicCommentsDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = dataframe[\"clean_text\"].tolist()\n",
    "        # Convert labels to float tensor for multi-label classification\n",
    "        self.labels = dataframe[label_cols].values.astype(float)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        # Tokenize the text\n",
    "        tokens = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # Squeeze to remove extra dimension\n",
    "        input_ids = tokens[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = tokens[\"attention_mask\"].squeeze(0)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": label\n",
    "        }\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "train_dataset = ToxicCommentsDataset(train_df, tokenizer, max_length=256)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899c37a-0e98-4422-8b80-d66bcce0baff",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a4e6eb3-8b87-458d-83c7-1e79e9b43431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ethan\\anaconda3\\envs\\ml\\Lib\\site-packages\\transformers\\optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_10404\\3001790938.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for multi-label classification (6 labels)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n",
    "model.to(device)\n",
    "\n",
    "# loss function BCEWithLogitsLoss for multi-label classification\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Enable automatic mixed precision\n",
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff7c11-2d0a-4415-a032-f75b6d73a7ba",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7f8f051-eb3e-465f-af03-497cccd8a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ethan\\AppData\\Local\\Temp\\ipykernel_10404\\1209766155.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n",
      "Epoch 1: 100%|███████████████████████████████████████████████████████| 9974/9974 [41:29<00:00,  4.01it/s, loss=0.00098]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average Loss: 0.0501\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    loop = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        with amp.autocast():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits  \n",
    "            loss = loss_fn(logits, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} completed. Average Loss: {epoch_loss/len(train_dataloader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669eb76-6a5d-443c-8f13-71c2cb2ff5a1",
   "metadata": {},
   "source": [
    "### Prediction and Submission for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd62f6e2-2e9e-43b3-8941-7dd005d89d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Sample:\n",
      "   comment_id                                               text\n",
      "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
      "1      732895  Looks like be have an abuser , can you please ...\n",
      "2     1139051  I confess to having complete (and apparently b...\n",
      "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
      "4     2084821  It is not just you. This is a laundry list of ...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7537 entries, 0 to 7536\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   comment_id  7537 non-null   int64 \n",
      " 1   text        7537 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.9+ KB\n",
      "None\n",
      "Predicting toxicity scores...\n",
      "Submission file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "def predict_score(text):\n",
    "    model.eval()\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    tokens = {key: val.to(device) for key, val in tokens.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.sigmoid(logits).squeeze().tolist()  # Convert to list\n",
    "\n",
    "    # Assign different weights to different toxicity labels\n",
    "    weights = [1.0, 1.7, 1.3, 1.4, 1.2, 1.5]  # Adjust as needed\n",
    "\n",
    "    # Compute weighted sum instead of simple sum\n",
    "    score = sum(p * w for p, w in zip(probabilities, weights))\n",
    "\n",
    "    return score\n",
    "\n",
    "# Load test data for scoring\n",
    "test_df = pd.read_csv(\"comments_to_score.csv\")\n",
    "print(\"Test Data Sample:\")\n",
    "print(test_df.head())\n",
    "print(test_df.info())\n",
    "\n",
    "# Apply prediction function\n",
    "print(\"Predicting toxicity scores...\")\n",
    "test_df[\"score\"] = test_df[\"text\"].apply(predict_score)\n",
    "\n",
    "# Create the submission file\n",
    "submission_df = test_df[[\"comment_id\", \"score\"]]\n",
    "submission_df.to_csv(\"submission1.csv\", index=False)\n",
    "print(\"Submission file saved as submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d0c75-e4cd-4c05-aea0-392f9bffd64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
